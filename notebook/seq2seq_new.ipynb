{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append('../')  # 返回notebook的上一级目录\n",
    "# sys.path.append('E:\\GitHub\\QA-abstract-and-reasoning')  # 效果同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "np.set_printoptions(suppress=True)\n",
    "from utils.saveLoader import *\n",
    "from utils.config import *\n",
    "\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "import tensorflow as tf\n",
    "# from model_layer import seq2seq_model\n",
    "import time\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[限制gpu内存增长](https://tensorflow.google.cn/guide/gpu#limiting_gpu_memory_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config_gpu import config_gpu\n",
    "config_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y,test_x = load_train_dataset()  # 数据集\n",
    "vocab,vocab_reversed = load_vocab(VOCAB_PAD)  # vocab\n",
    "embedding_matrix = np.loadtxt(EMBEDDING_MATRIX_PAD)  # 预训练层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 32566, 'max_enc_len': 260, 'max_dec_len': 33, 'embed_size': 300, 'enc_units': 512, 'attn_units': 10, 'dec_units': 512, 'batch_size': 8, 'epochs': 5}\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"vocab_size\"] = len(vocab)\n",
    "params[\"max_enc_len\"] = train_x.shape[1]  # 260\n",
    "params[\"max_dec_len\"] = train_y.shape[1]  # 33\n",
    "params[\"embed_size\"] = embedding_matrix.shape[1]\n",
    "params[\"enc_units\"] = 512\n",
    "params[\"attn_units\"] = 10\n",
    "params[\"dec_units\"] = 512\n",
    "params[\"batch_size\"] = 8\n",
    "params[\"epochs\"] = 5\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取部分数据进行训练\n",
    "sample_num=64\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_x[:sample_num], train_y[:sample_num])).shuffle(params[\"batch_size\"]*2+1)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 65//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_tf2.seq2seq_model import Seq2Seq\n",
    "model=Seq2Seq(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 基本参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集的长度\n",
    "# BUFFER_SIZE = len(train_X)\n",
    "\n",
    "# 输入的长度\n",
    "# max_length_inp=train_X.shape[1]\n",
    "# 输出的长度\n",
    "# max_length_targ=train_Y.shape[1]\n",
    "\n",
    "# BATCH_SIZE = 8\n",
    "\n",
    "# 训练一轮需要迭代多少步\n",
    "steps_per_epoch = len(train_X)//BATCH_SIZE\n",
    "\n",
    "# 词向量维度\n",
    "# embedding_dim = 300\n",
    "\n",
    "# 隐藏层单元数\n",
    "# units = 32\n",
    "\n",
    "# 词表大小\n",
    "# vocab_size = len(vocab)\n",
    "\n",
    "# 构建训练集\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y)).shuffle(BUFFER_SIZE)\n",
    "# dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 构建Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值具体是什么可以查看[RNN文档](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/RNN)\n",
    "Output shape:\n",
    "\n",
    "- If return_state: a list of tensors. The first tensor is the output. The remaining tensors are the last states, each with shape (batch_size, state_size), where state_size could be a high dimension tensor shape.\n",
    "\n",
    "\n",
    "- If return_sequences: N-D tensor with shape (batch_size, timesteps, output_size), where output_size could be a high dimension tensor shape, or (timesteps, batch_size, output_size) when time_major is True.\n",
    "\n",
    "\n",
    "- Else, N-D tensor with shape (batch_size, output_size), where output_size could be a high dimension tensor shape.\n",
    "\n",
    "[这篇文章](https://blog.csdn.net/u011327333/article/details/78501054)分析了`return_state` 和 `return_sequences`取True 或 False 的四种情况\n",
    "\n",
    "[GRU官方文档](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/GRU#class_gru)\n",
    "\n",
    "<img src=\"./picture/encoder.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim ,embedding_matrix , enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units # whats this\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,weights=[embedding_matrix],trainable=False)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        # print(\"after embedding\",x.shape)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        # (一批数据大小, 隐层的维数)\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32566, 300, 32, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, embedding_dim, units, BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32566, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim,embedding_matrix, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 260)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13, shape=(8, 260), dtype=int32, numpy=\n",
       "array([[32562,   403,   985, ..., 32565, 32565, 32565],\n",
       "       [32562,   816, 26474, ..., 32565, 32565, 32565],\n",
       "       [32562,  1445,    81, ...,    31,     2, 32564],\n",
       "       ...,\n",
       "       [32562,   920,    30, ..., 32565, 32565, 32565],\n",
       "       [32562,  2026,   278, ..., 32565, 32565, 32565],\n",
       "       [32562, 32563,  1033, ..., 32565, 32565, 32565]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.cast(train_x[:BATCH_SIZE], dtype=tf.int32)\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (8, 260, 32)\n",
      "Encoder Hidden state shape: (batch size, units) (8, 32)\n"
     ]
    }
   ],
   "source": [
    "# 感觉这个output的shape很像权重\n",
    "sample_output, sample_hidden = encoder(x, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture/gru.png\" width = \"50%\" height = \"50%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 构建Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        \n",
    "        # query为上次的GRU隐藏层\n",
    "        # values为编码器的编码结果enc_output\n",
    "        # 在seq2seq模型中，St是后面的query向量，而编码过程的隐藏状态hi是values。\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        \n",
    "        # 计算注意力权重值\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # # 使用注意力权重*编码器输出作为返回值，将来会作为解码器的输入\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vector shape: (batch size, units) (8, 32)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (8, 260, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "context_vector, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"context_vector shape: (batch size, units) {}\".format(context_vector.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个样本是260行1024列的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出是260行10列的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 构建Decoder\n",
    "\n",
    "<img src=\"./picture/decoder.png\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,weights=[embedding_matrix],trainable=False)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)  # 为了softmax层数要保持一致\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (8, 32566)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size, embedding_dim,embedding_matrix, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器和损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SparseCategoricalCrossentropy](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "pad_index=vocab['<PAD>']\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # 相当于把<PAD>给过滤了，词如果是<PAD>那它对应位置的mask为 False\n",
    "    # real = [0, 1, 2] pad_index = 2 --> mask = [True, Ture, False]\n",
    "    # 用于后面不计算<PAD>词的损失\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, pad_index))\n",
    "    # 计算损失\n",
    "    # real = [0, 1, 2] pred = [[.91,.4,.5],[.0, .88, .1],[.3, .3, .94]]\n",
    "    loss_ = loss_object(real, pred)\n",
    "    # bool型转float(与loss_的数据类型一致)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    # 不计算<PAD>词损失值\n",
    "    loss_ *= mask\n",
    "    # 返回损失值之和\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存点设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'data/checkpoints/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/checkpoints/training_checkpoints\\\\ckpt'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1. 构建encoder\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        # 2. 复制\n",
    "        dec_hidden = enc_hidden\n",
    "        # 3. <START> * BATCH_SIZE \n",
    "        # shape: (BATCH_SIZE, 1)\n",
    "        dec_input = tf.expand_dims([vocab['<START>']] * BATCH_SIZE, 1)\n",
    "    \n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        # 这里跟decoder有点区别，是一个一个输入固定位置的词 dec_input的 shape: (BATCH_SIZE, 1)\n",
    "        # 例如一批数据64句话，第一轮输入<START>,第二轮输入所有句子的第一个词...\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # targ.shape = (BATCH_SIZE, len_train_Y) 第二个参数是句子长度\n",
    "            # decoder(x, hidden, enc_output)\n",
    "            # predictions用于sotfmax的(BATCH_SIZE, VOCAB_SIZE)向量\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            # 为什么损失值是累加的: 注意这里是targ[:, t]不是targ[:t]\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            # 为下一个输入做准备\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)  # shape: (BATCH_SIZE, 1)\n",
    "\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.9985\n",
      "Epoch 1 Batch 1 Loss 4.5655\n",
      "Epoch 1 Batch 2 Loss 6.9262\n",
      "Epoch 1 Batch 3 Loss 4.6807\n",
      "Epoch 1 Batch 4 Loss 4.8363\n",
      "Epoch 1 Batch 5 Loss 3.9708\n",
      "Epoch 1 Batch 6 Loss 4.8331\n",
      "Epoch 1 Batch 7 Loss 4.9101\n",
      "Epoch 1 Loss 4.9652\n",
      "Time taken for 1 epoch 116.68947958946228 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "TRAIN = True\n",
    "if TRAIN:\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        # 初始化隐藏层\n",
    "        enc_hidden = encoder.initialize_hidden_state()\n",
    "        total_loss = 0\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "            # \n",
    "            batch_loss = train_step(inp, targ, enc_hidden)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            if batch % 1 == 0:\n",
    "                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                             batch,\n",
    "                                                             batch_loss.numpy()))\n",
    "        # saving (checkpoint) the model every 2 epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                          total_loss / steps_per_epoch))\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答\n",
    "* The evaluate function is similar to the training loop, except we don't use <u>*teacher forcing*</u> here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import Preprocess\n",
    "pp = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='奔驰的方向机重，助力泵，方向机都换了还是一样'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ztn\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.913 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'奔驰 方向机 重 助力 泵 方向机 都 换'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.sentence_proc(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 260)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.sentence_proc_eval(sentence,max_length_inp-2,vocab).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 260)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.data_loader import preprocess_sentence\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'STSong'  # 显示中文\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    # 需要整合下自己的预处理\n",
    "    # 这里max_length_inp-2为何要-2\n",
    "    # 原本计算得到最大长度为258，经过pad后长度变为260了，如果这里继续用260，input长度会变成262\n",
    "    inputs = pp.sentence_proc_eval(sentence,max_length_inp-2,vocab)\n",
    "\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "    \n",
    "    hidden = [tf.zeros((1, units))]  # 这个是不是可以调之前的encoder里的初始化方法\n",
    "    \n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    \n",
    "    dec_input = tf.expand_dims([vocab['<START>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        \n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        \n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        # predictions shape: (1, vocab_size) 和numpy 的argmax()还是有点区别的\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += vocab_reversed[predicted_id] + ' '\n",
    "        if vocab_reversed[predicted_id] == '<STOP>':\n",
    "            # 去掉结尾的空格\n",
    "            return result.strip(), sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    sentence = pp.sentence_proc(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 奔驰 方向机 重 助力 泵 方向机 都 换\n",
      "Predicted translation: 这种 情况 只能 6080 现象 问题 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 市面上 轮胎 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence='奔驰的方向机重，助力泵，方向机都换了还是一样'\n",
    "translate(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
