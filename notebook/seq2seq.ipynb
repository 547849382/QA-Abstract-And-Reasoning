{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append('../')  # 返回notebook的上一级目录\n",
    "# sys.path.append('E:\\GitHub\\QA-abstract-and-reasoning')  # 效果同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "np.set_printoptions(suppress=True)\n",
    "from utils.loader import *\n",
    "from utils.config import *\n",
    "\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "import tensorflow as tf\n",
    "# from model_layer import seq2seq_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[限制gpu内存增长](https://tensorflow.google.cn/guide/gpu#limiting_gpu_memory_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "#     try:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#             gpus[0],\n",
    "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         # Virtual devices must be set before GPUs have been initialized\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y,test_x = load_dataset()  # 数据集\n",
    "vocab_index,index_vocab = load_vocab(VOCAB_INDEX_PAD)  # vocab\n",
    "embedding_matrix = np.loadtxt(EMBEDDING_MATRIX_PAD)  # 预训练层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入长度：260\n",
      "输出长度：33\n",
      "词表大小：32566\n"
     ]
    }
   ],
   "source": [
    "# 输入的长度  train_X.shape -> (82871, 261)\n",
    "input_length = train_x.shape[1]\n",
    "# 输出的长度  train_Y.shape -> (82871, 34)\n",
    "output_sequence_length = train_y.shape[1]\n",
    "# 词表大小\n",
    "vocab_size=len(vocab_index)\n",
    "print(\"输入长度：{}\\n输出长度：{}\\n词表大小：{}\".format(input_length, output_sequence_length, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 基本参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取部分数据进行训练\n",
    "sample_num=64\n",
    "train_X=train_x[:sample_num]\n",
    "train_Y=train_y[:sample_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集的长度\n",
    "BUFFER_SIZE = len(train_X)\n",
    "\n",
    "# 输入的长度\n",
    "max_length_inp=train_X.shape[1]\n",
    "# 输出的长度\n",
    "max_length_targ=train_Y.shape[1]\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# 训练一轮需要迭代多少步\n",
    "steps_per_epoch = len(train_X)//BATCH_SIZE\n",
    "\n",
    "# 词向量维度\n",
    "embedding_dim = 300\n",
    "\n",
    "# 隐藏层单元数\n",
    "units = 32\n",
    "\n",
    "# 词表大小\n",
    "vocab_size = len(vocab_index)\n",
    "\n",
    "# 构建训练集\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 构建Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值具体是什么可以查看[RNN文档](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/RNN)\n",
    "Output shape:\n",
    "\n",
    "- If return_state: a list of tensors. The first tensor is the output. The remaining tensors are the last states, each with shape (batch_size, state_size), where state_size could be a high dimension tensor shape.\n",
    "\n",
    "\n",
    "- If return_sequences: N-D tensor with shape (batch_size, timesteps, output_size), where output_size could be a high dimension tensor shape, or (timesteps, batch_size, output_size) when time_major is True.\n",
    "\n",
    "\n",
    "- Else, N-D tensor with shape (batch_size, output_size), where output_size could be a high dimension tensor shape.\n",
    "\n",
    "[这篇文章](https://blog.csdn.net/u011327333/article/details/78501054)分析了`return_state` 和 `return_sequences`取True 或 False 的四种情况\n",
    "\n",
    "[GRU官方文档](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/GRU#class_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim ,embedding_matrix , enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units # whats this\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,weights=[embedding_matrix],trainable=False)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        # print(\"after embedding\",x.shape)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        # (一批数据大小, 隐层的维数)\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32566, 300, 32, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, embedding_dim, units, BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32566, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim,embedding_matrix, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 260)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(8, 260), dtype=int32, numpy=\n",
       "array([[32562,   403,   985, ..., 32565, 32565, 32565],\n",
       "       [32562,   816, 26474, ..., 32565, 32565, 32565],\n",
       "       [32562,  1445,    81, ...,    31,     2, 32564],\n",
       "       ...,\n",
       "       [32562,   920,    30, ..., 32565, 32565, 32565],\n",
       "       [32562,  2026,   278, ..., 32565, 32565, 32565],\n",
       "       [32562, 32563,  1033, ..., 32565, 32565, 32565]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.cast(train_x[:BATCH_SIZE], dtype=tf.int32)\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=17, shape=(8, 32), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (8, 260, 32)\n",
      "Encoder Hidden state shape: (batch size, units) (8, 32)\n"
     ]
    }
   ],
   "source": [
    "# 感觉这个output的shape很像权重\n",
    "sample_output, sample_hidden = encoder(x, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture/gru.png\" width = \"50%\" height = \"50%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 构建Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        \n",
    "        # query为上次的GRU隐藏层\n",
    "        # values为编码器的编码结果enc_output\n",
    "        # 在seq2seq模型中，St是后面的query向量，而编码过程的隐藏状态hi是values。\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        \n",
    "        # 计算注意力权重值\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # # 使用注意力权重*编码器输出作为返回值，将来会作为解码器的输入\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vector shape: (batch size, units) (8, 32)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (8, 260, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "context_vector, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"context_vector shape: (batch size, units) {}\".format(context_vector.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.keras.layers.Dense(10)\n",
    "w2 = tf.keras.layers.Dense(10)\n",
    "v = tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 260, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个样本是260行1024列的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 260, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1(sample_output).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出是260行10列的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.weights[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 构建Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim,embedding_matrix, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,weights=[embedding_matrix],trainable=False)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)  # 为了softmax层数要保持一致\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (8, 32566)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size, embedding_dim,embedding_matrix, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器和损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SparseCategoricalCrossentropy](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "pad_index=vocab_index['<PAD>']\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # 相当于把<PAD>给过滤了，词如果是<PAD>那它对应位置的mask为 False\n",
    "    # real = [0, 1, 2] pad_index = 2 --> mask = [True, Ture, False]\n",
    "    # 用于后面不计算<PAD>词的损失\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, pad_index))\n",
    "    # 计算损失\n",
    "    # real = [0, 1, 2] pred = [[.91,.4,.5],[.0, .88, .1],[.3, .3, .94]]\n",
    "    loss_ = loss_object(real, pred)\n",
    "    # bool型转float(与loss_的数据类型一致)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    # 不计算<PAD>词损失值\n",
    "    loss_ *= mask\n",
    "    # 返回损失值之和\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存点设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'data/checkpoints/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/checkpoints/training_checkpoints\\\\ckpt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1. 构建encoder\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        # 2. 复制\n",
    "        dec_hidden = enc_hidden\n",
    "        # 3. <START> * BATCH_SIZE \n",
    "        # shape: (BATCH_SIZE, 1)\n",
    "        dec_input = tf.expand_dims([vocab_index['<START>']] * BATCH_SIZE, 1)\n",
    "    \n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        # 这里跟decoder有点区别，是一个一个输入固定位置的词 dec_input的 shape: (BATCH_SIZE, 1)\n",
    "        # 例如一批数据64句话，第一轮输入<START>,第二轮输入所有句子的第一个词...\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # targ.shape = (BATCH_SIZE, len_train_Y) 第二个参数是句子长度\n",
    "            # decoder(x, hidden, enc_output)\n",
    "            # predictions用于sotfmax的(BATCH_SIZE, VOCAB_SIZE)向量\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            # 为什么损失值是累加的: 注意这里是targ[:, t]不是targ[:t]\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            # 为下一个输入做准备\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)  # shape: (BATCH_SIZE, 1)\n",
    "\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer decoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1 Batch 0 Loss 6.3372\n",
      "Epoch 1 Batch 1 Loss 5.4315\n",
      "Epoch 1 Batch 2 Loss 3.8952\n",
      "Epoch 1 Batch 3 Loss 4.6794\n",
      "Epoch 1 Batch 4 Loss 3.9709\n",
      "Epoch 1 Batch 5 Loss 6.3656\n",
      "Epoch 1 Batch 6 Loss 3.4559\n",
      "Epoch 1 Batch 7 Loss 5.5768\n",
      "Epoch 1 Loss 4.9640\n",
      "Time taken for 1 epoch 48.269983530044556 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "TRAIN = True\n",
    "if TRAIN:\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        # 初始化隐藏层\n",
    "        enc_hidden = encoder.initialize_hidden_state()\n",
    "        total_loss = 0\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "            # \n",
    "            batch_loss = train_step(inp, targ, enc_hidden)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            if batch % 1 == 0:\n",
    "                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                             batch,\n",
    "                                                             batch_loss.numpy()))\n",
    "        # saving (checkpoint) the model every 2 epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                          total_loss / steps_per_epoch))\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答\n",
    "* The evaluate function is similar to the training loop, except we don't use <u>*teacher forcing*</u> here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import *\n",
    "pp = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='奔驰的方向机重，助力泵，方向机都换了还是一样'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Light\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.679 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'奔驰 方向机 重 助力 泵 方向机 都 换'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.sentence_proc(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 260)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.sentence_proc_eval(sentence,max_length_inp-2,vocab_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 260)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.data_loader import preprocess_sentence\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'STSong'  # 显示中文\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    # 需要整合下自己的预处理\n",
    "    # 这里max_length_inp-2为何要-2\n",
    "    # 原本计算得到最大长度为258，经过pad后长度变为260了，如果这里继续用260，input长度会变成262\n",
    "    inputs = pp.sentence_proc_eval(sentence,max_length_inp-2,vocab_index)\n",
    "\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "    \n",
    "    hidden = [tf.zeros((1, units))]  # 这个是不是可以调之前的encoder里的初始化方法\n",
    "    \n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    \n",
    "    dec_input = tf.expand_dims([vocab_index['<START>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        \n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        \n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        # predictions shape: (1, vocab_size) 和numpy 的argmax()还是有点区别的\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += index_vocab[predicted_id] + ' '\n",
    "        if index_vocab[predicted_id] == '<STOP>':\n",
    "            # 去掉结尾的空格\n",
    "            return result.strip(), sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    sentence = pp.sentence_proc(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 奔驰 方向机 重 助力 泵 方向机 都 换\n",
      "Predicted translation: 这种 情况 分析 <STOP>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence='奔驰的方向机重，助力泵，方向机都换了还是一样'\n",
    "translate(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 漏 机油 具体 部位 发动机 变速器 正中间 位置 拍 中间 上面 上 已经 看见\n",
      "Predicted translation: 这种 情况 分析 <STOP>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence='漏机油 具体 部位 发动机 变速器 正中间 位置 拍 中间 上面 上 已经 看见'\n",
    "translate(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2.0]",
   "language": "python",
   "name": "conda-env-tf2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
